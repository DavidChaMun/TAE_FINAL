{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Para la implementación de este método, se hace uso del módulo DecisionTreeClassifier de sklearn para el motor de predicción, además se hace uso del módulo LabelEncoder y OneHotEncoder para la generación de las variables dummies a partir de las variables categóricas. Al final con una matriz de confusión se podrá observar la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargando Dependencias, Estas se pueden encontrar en requirements.txt\n",
    "import re\n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble.forest import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de datos\n",
    "Se hace uso de la base obtenida en https://archive.ics.uci.edu/ml/datasets/Adult, que busca predecir si los ingresos de un adulto son o no mayores a 50k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se leen las bases de datos, tanto de entrenamiento como de prueba\n",
    "train_data_set = pd.read_csv(\"data/dataset_tae_final_no_na_mod.csv\", encoding = \"ISO-8859-1\")\n",
    "test_data_set = pd.read_csv(\"data/test_tae_no_na_mod.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Se hace una limpieza de la base de datos deprueba, pues presenta una diferencia en el formato de la variable a predecir\n",
    "test_data_set[\"income\"]=test_data_set[\"income\"].replace(\" <=50K.\", \" <=50K\")\n",
    "test_data_set[\"income\"]=test_data_set[\"income\"].replace(\" >50K.\", \" >50K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El modelo predictor\n",
    "La clase TAERandomForestClassifier sera el modelo, al crear una instancia de esta clase el modelo se inicializa sin ser entrenado con unos meta-parámetros por defecto para su entrenamiento, que en este caso ya son los óptimos: Esto se determinó mediante un ciclo que prueba cada uno de ellos en un rango, guarda sus precisiones y escoge la más alta.\n",
    "\n",
    "### Metaparametros\n",
    "Se tienen en cuenta 3 meta parametros:  \n",
    "- Numero de estimadores: 100.  \n",
    "Este meta parámetro determina el numero interno de modelos de árbol que va a usar, se determina que 100 es un numero optimo ya que la razón de ganancia de precisión contra el tiempo de entrenamiento no es lo suficientemente significativo para el sacrificio en el desempeño del modelo\n",
    "- Numero de categorias: 7.  \n",
    "Este meta parámetro determina cuantas características de la base de datos va a usar por modelo como máximo\n",
    "- Maximo de profundidad: 16.  \n",
    "Este meta parámetro determina el máximo de niveles que los arboles pueden tener al ser generados en el bosque\n",
    "\n",
    "\n",
    "### Metodos\n",
    "La clase usa 6 métodos, 2 métodos para la codificación de las variables categóricas en dummies, donde encode_fit hace la categorización en el entrenamiento y entrega un diccionario para futuras categorizaciones de dummies. El método encode hace la categorización en dummies de las futuras entradas. Tenemos un metodo fit, que toma una base de datos con la cual se entrena el modelo, luego un método predict que usa el modelo entrenado para predecir con entradas nuevas, ambos métodos reciben la base de datos en formato panda. Por último, tenemos el método cal_conf_matrix que nos imprime la matriz de confusión con base en una base de datos de prueba y la precisión de nuestro modelo, por último,\n",
    "tenemos set_meta que nos permite modificar los meta-parámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAERandomForestClassifier(object):\n",
    "    lab_encoders = {}\n",
    "    dummy_encoder = None\n",
    "    rfc_model = None\n",
    "    n_estimators = 100\n",
    "    max_features = 5\n",
    "    max_depth = 16\n",
    "    \n",
    "    def encode_fit(self, cat_data):\n",
    "        #Encodes string to numeric labels\n",
    "        tdc_set_encoded = cat_data.copy(deep=True)\n",
    "        for cn in cat_data.columns:\n",
    "            self.lab_encoders[cn] = preprocessing.LabelEncoder()\n",
    "            self.lab_encoders[cn].fit(cat_data[str(cn)])\n",
    "            tdc_set_encoded[str(cn)] = self.lab_encoders[cn].transform(cat_data[str(cn)])\n",
    "        \n",
    "        #Encodes to dummy dataset\n",
    "        self.dummy_encoder = preprocessing.OneHotEncoder(categories=\"auto\")\n",
    "        self.dummy_encoder.fit(tdc_set_encoded[cat_data.columns])\n",
    "        \n",
    "        #print(len(self.dummy_encoder.get_feature_names()))\n",
    "        \n",
    "        encoded_cat_data = pd.DataFrame(data=self.dummy_encoder.transform(tdc_set_encoded).todense(), columns=self.dummy_encoder.get_feature_names())\n",
    "        return encoded_cat_data\n",
    "    \n",
    "    def encode(self, cat_data):\n",
    "        for cn in cat_data.columns:\n",
    "              cat_data[str(cn)] = self.lab_encoders[cn].transform(cat_data[str(cn)]) \n",
    "        \n",
    "        \n",
    "        #Encodes to dummy dataset\n",
    "        encoded_cat_data = pd.DataFrame(data=self.dummy_encoder.transform(cat_data).todense(), columns=self.dummy_encoder.get_feature_names())    \n",
    "        return encoded_cat_data       \n",
    "    def fit(self, x_train, y_train, cat_cols, num_cols):\n",
    "        #Separates dataset in categorical and numbers\n",
    "        x_train_num = x_train[num_cols].copy(deep=True)\n",
    "        x_train_cat = x_train[cat_cols].copy(deep=True)\n",
    "        \n",
    "        x_train_cat = self.encode_fit(x_train_cat)\n",
    "        \n",
    "        x_train_num.reset_index(drop=True, inplace=True)\n",
    "        x_train_cat.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        f_x_train = pd.concat([x_train_num, x_train_cat], axis=1)\n",
    "\n",
    "        self.rfc_model = RandomForestClassifier(n_estimators=self.n_estimators, criterion=\"entropy\", \n",
    "                                                max_features=self.max_features, max_depth=self.max_depth)\n",
    "        self.rfc_model = self.rfc_model.fit(f_x_train, y_train)\n",
    "        \n",
    "    def predict(self, x_predict, cat_cols, num_cols):\n",
    "        #Separates dataset in categorical and numbers\n",
    "        x_predict_num = x_predict[num_cols].copy(deep=True)\n",
    "        x_predict_cat = x_predict[cat_cols].copy(deep=True)\n",
    "        \n",
    "        x_predict_cat = self.encode(x_predict_cat)\n",
    "        f_x_predict = pd.concat([x_predict_num, x_predict_cat], axis=1)\n",
    "        y_pred = self.rfc_model.predict(f_x_predict)\n",
    "        return y_pred\n",
    "    \n",
    "    def cal_conf_matrix(self, x_test, y_test, catego_columns, numeric_cols):\n",
    "        y_pred = self.predict(x_test, catego_columns, numeric_cols)\n",
    "        # [[VP, FP], [FN, VN]]\n",
    "        print(\"Matriz de confusión:\")\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "        #Correr varias veces y ver como varia. Basado en el indice de jaccard\n",
    "        print(\"Precisión:\", metrics.accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        return metrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    def set_meta(self, max_features, n_estimators, max_depth):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[10841   518]\n",
      " [ 1622  2078]]\n",
      "Precisión: 0.8578922903247228\n"
     ]
    }
   ],
   "source": [
    "# Se una instancia del odelo, se entrega con los datos de entrenamiento y se valida con los datos de prueba\n",
    "catego_columns = ['education', 'workclass', 'marital_status', 'ocupation', 'ethnicity', 'gender', 'native_country']\n",
    "numeric_cols = ['age', 'fnlwgt', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "\n",
    "forest = TAERandomForestClassifier()\n",
    "forest.fit(train_data_set.loc[:,train_data_set.columns!=\"income\",],train_data_set[\"income\"], catego_columns, numeric_cols)\n",
    "m = forest.cal_conf_matrix(test_data_set.loc[:,test_data_set.columns!=\"income\",], test_data_set[\"income\"], catego_columns, numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados Matriz de Confusión\n",
    "\n",
    "Real vs  Pedicha | <=50k | >50k \n",
    "---- | ---- | ---- \n",
    "<=50k | 10788 | 571 |\n",
    " >50k | 1561 | 2139 \n",
    "\n",
    "Logrando una precision del: 86%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
