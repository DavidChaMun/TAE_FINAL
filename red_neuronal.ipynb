{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal utilizando Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora construiremos una red neuronal utilizando la libreria de Keras para implementar tensorflow.\n",
    "Utilizaremos la base de datos sin valores faltantes para entrenar el modelo, y mediante validación cruzada probaremos su efectividad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "import qgrid\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset_tae_final_no_na_mod.csv')\n",
    "test = pd.read_csv('test_tae_no_na_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b6285efa8449628707a07a48efa6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qqview = qgrid.show_grid(train)\n",
    "qqview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestra variable objetivo y nuestras caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "fnlwgt             int64\n",
       "education         object\n",
       "marital_status    object\n",
       "ocupation         object\n",
       "ethnicity         object\n",
       "gender            object\n",
       "capital_gain       int64\n",
       "capital_loss       int64\n",
       "hours_per_week     int64\n",
       "native_country    object\n",
       "income            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = list(train.columns)\n",
    "features = column[:-1]\n",
    "target_name = column[-1]\n",
    "#Chequeo de tipos de las variables\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tenemos variables categoricas, debemos transformarlas a variables dummies par apoder crear la red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "catego_columns = ['education', 'workclass', 'marital_status', \n",
    "             'ethnicity', 'income','gender',\n",
    "                  'native_country', 'ocupation']\n",
    "#Transformamos variables object a categoricas\n",
    "for col in catego_columns:\n",
    "    train[col] = pd.Categorical(train[col])\n",
    "    test[col] = pd.Categorical(test[col])\n",
    "\n",
    "#Transformamos nuestra variable de objetivo para la clasificacion\n",
    "train[target_name] = train[target_name].cat.codes\n",
    "test[target_name] = test[target_name].cat.codes\n",
    "\n",
    "#Creamos variables dummies con las categoricas\n",
    "train_dataset=pd.get_dummies(train)\n",
    "test_dataset=pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequeamos que las variables de nuestro conjunto de entrenamiento sean las mismas que las de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for elem in list(train_dataset.columns):\n",
    "    if not((elem in list(test_dataset.columns))):\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos la variable encontrada:\n",
    "test_dataset['native_country_ Holand-Netherlands'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_n = ['age', 'education_num']\n",
    "temp = train[temp_n]\n",
    "target = temp.pop(\"age\")\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((temp.values, target.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
